{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 01: Data Collection and Preprocessing\n",
    "\n",
    "This notebook demonstrates fundamental data collection and preprocessing techniques using Python and pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Load the Dataset\n",
    "\n",
    "In this step, we load the retail transactions CSV file using pandas and inspect the first few rows to understand the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import pandas library\nimport pandas as pd\n\n# Load the CSV file into a DataFrame\ndf = pd.read_csv('data/Retail_Transactions_Dataset.csv')\n\n# Display the first 3 rows\ndf.head(3)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Data Structure Choice\n",
    "\n",
    "### Why pandas DataFrame?\n",
    "\n",
    "We use a **pandas DataFrame** to store our retail transactions data for the following reasons:\n",
    "\n",
    "| Criteria | DataFrame Advantage |\n",
    "|----------|---------------------|\n",
    "| **Tabular format** | CSV data is naturally row-column structured; DataFrames mirror this exactly |\n",
    "| **Mixed data types** | Our dataset contains strings (`Product`, `City`), numbers (`Total_Cost`, `Total_Items`), and dates (`Date`) ‚Äî DataFrames handle heterogeneous columns efficiently |\n",
    "| **Built-in methods** | Pandas provides optimized functions for filtering, grouping, aggregating, and cleaning data |\n",
    "| **Memory efficiency** | DataFrames use NumPy arrays under the hood, enabling vectorized operations |\n",
    "| **Ecosystem integration** | Seamless compatibility with visualization libraries (matplotlib, seaborn) and ML frameworks (scikit-learn) |\n",
    "\n",
    "### Alternatives Considered\n",
    "\n",
    "- **Python lists/dicts**: No built-in support for column operations or missing data handling\n",
    "- **NumPy arrays**: Require homogeneous data types; not ideal for mixed-type tabular data\n",
    "- **SQL database**: Overkill for a single-file analysis; adds setup complexity\n",
    "\n",
    "**Conclusion**: pandas DataFrame is the optimal choice for exploratory data analysis and preprocessing of structured CSV data."
   ]
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Step 3: Transaction Class\n\nWe define a `Transaction` class to encapsulate individual transaction records. This provides:\n- **Encapsulation**: Each transaction is a self-contained object\n- **Data cleaning**: The `clean()` method standardizes and sanitizes field values\n- **Calculations**: The `total()` method computes the transaction total",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class Transaction:\n    \"\"\"\n    Represents a single retail transaction.\n    \n    Attributes:\n        transaction_id: Unique identifier for the transaction\n        date: Date of the transaction\n        customer_name: Name of the customer\n        product: Product purchased\n        quantity: Number of items (Total_Items)\n        price: Cost of the transaction (Total_Cost)\n        city: City where the transaction occurred\n        promotion: Promotion/coupon code applied\n    \"\"\"\n    \n    def __init__(self, row):\n        \"\"\"Initialize a Transaction from a DataFrame row.\"\"\"\n        self.transaction_id = row.get('Transaction_ID', None)\n        self.date = row.get('Date', None)\n        self.customer_name = row.get('Customer_Name', None)\n        self.product = row.get('Product', None)\n        self.quantity = row.get('Total_Items', 0)\n        self.price = row.get('Total_Cost', 0.0)\n        self.city = row.get('City', None)\n        self.promotion = row.get('Promotion', None)\n    \n    def clean(self):\n        \"\"\"\n        Clean and standardize transaction data.\n        \n        Returns:\n            self: The Transaction instance (for method chaining)\n        \"\"\"\n        # Strip whitespace from string fields\n        if isinstance(self.customer_name, str):\n            self.customer_name = self.customer_name.strip().title()\n        \n        if isinstance(self.product, str):\n            self.product = self.product.strip().title()\n        \n        if isinstance(self.city, str):\n            self.city = self.city.strip().title()\n        \n        if isinstance(self.promotion, str):\n            self.promotion = self.promotion.strip().upper()\n        \n        # Handle missing/invalid numeric values\n        try:\n            self.quantity = int(self.quantity) if self.quantity else 0\n        except (ValueError, TypeError):\n            self.quantity = 0\n        \n        try:\n            self.price = float(self.price) if self.price else 0.0\n        except (ValueError, TypeError):\n            self.price = 0.0\n        \n        return self\n    \n    def total(self):\n        \"\"\"\n        Calculate the transaction total.\n        \n        Returns:\n            float: The total cost of the transaction\n        \"\"\"\n        return float(self.price)\n    \n    def __repr__(self):\n        \"\"\"String representation for debugging.\"\"\"\n        return f\"Transaction(id={self.transaction_id}, product={self.product}, total={self.total():.2f})\"\n\n\n# --- Demo: Create and clean a Transaction ---\n# Get the first row as a dictionary\nsample_row = df.iloc[0].to_dict()\n\n# Create a Transaction object\ntxn = Transaction(sample_row)\n\n# Clean the transaction data\ntxn.clean()\n\n# Display the transaction\nprint(f\"Transaction ID: {txn.transaction_id}\")\nprint(f\"Customer:       {txn.customer_name}\")\nprint(f\"Product:        {txn.product}\")\nprint(f\"Quantity:       {txn.quantity}\")\nprint(f\"City:           {txn.city}\")\nprint(f\"Promotion:      {txn.promotion}\")\nprint(f\"Total:          ${txn.total():.2f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Step 4: Bulk Load Transactions\n\nConvert the entire DataFrame into a list of `Transaction` objects. This demonstrates:\n- Iterating over DataFrame rows\n- Creating objects in bulk\n- Applying the `clean()` method to each transaction",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Convert DataFrame rows to a list of Transaction objects\n# Each row becomes a Transaction, then we call clean() on it\n\ntransactions = []\n\nfor index, row in df.iterrows():\n    # Convert row to dictionary and create Transaction\n    txn = Transaction(row.to_dict())\n    \n    # Clean the transaction data\n    txn.clean()\n    \n    # Add to list\n    transactions.append(txn)\n\n# Display summary\nprint(f\"Total transactions loaded: {len(transactions):,}\")\nprint(f\"\\nFirst 3 transactions:\")\nfor t in transactions[:3]:\n    print(f\"  {t}\")\n\nprint(f\"\\nLast 3 transactions:\")\nfor t in transactions[-3:]:\n    print(f\"  {t}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Step 5: Data Profiling\n\nCompute basic statistics to understand the dataset:\n- **Price statistics**: min, mean, max\n- **Unique cities**: count of distinct shipping locations",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Extract prices from all transactions\nprices = [t.price for t in transactions]\n\n# Compute price statistics\nmin_price = min(prices)\nmax_price = max(prices)\nmean_price = sum(prices) / len(prices)\n\n# Get unique cities\ncities = set(t.city for t in transactions)\nunique_city_count = len(cities)\n\n# Display profiling results\nprint(\"=\" * 40)\nprint(\"DATA PROFILING RESULTS\")\nprint(\"=\" * 40)\n\nprint(f\"\\nüìä Price Statistics:\")\nprint(f\"   Min:  ${min_price:,.2f}\")\nprint(f\"   Mean: ${mean_price:,.2f}\")\nprint(f\"   Max:  ${max_price:,.2f}\")\n\nprint(f\"\\nüèôÔ∏è City Statistics:\")\nprint(f\"   Unique cities: {unique_city_count}\")\n\nprint(f\"\\nüìã Sample cities:\")\nfor city in sorted(cities)[:5]:\n    print(f\"   - {city}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Step 6: Identify Dirty Data\n\nBefore cleaning, we analyze the raw DataFrame to identify data quality issues:\n- **Missing values**: Null or NaN entries\n- **Duplicates**: Repeated transaction IDs\n- **Invalid values**: Negative prices, zero quantities\n- **Inconsistent formatting**: Mixed case, extra whitespace",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ============================================\n# DIRTY DATA IDENTIFICATION\n# ============================================\n\nprint(\"=\" * 50)\nprint(\"DIRTY DATA REPORT\")\nprint(\"=\" * 50)\n\n# --- 1. Missing Values ---\nprint(\"\\n1Ô∏è‚É£ MISSING VALUES\")\nprint(\"-\" * 30)\nmissing_counts = df.isnull().sum()\ntotal_missing = missing_counts.sum()\n\nif total_missing > 0:\n    for col, count in missing_counts.items():\n        if count > 0:\n            pct = (count / len(df)) * 100\n            print(f\"   {col}: {count:,} ({pct:.2f}%)\")\nelse:\n    print(\"   No missing values found\")\n\n# --- 2. Duplicate Transaction IDs ---\nprint(\"\\n2Ô∏è‚É£ DUPLICATE TRANSACTION IDs\")\nprint(\"-\" * 30)\nduplicate_ids = df[df.duplicated(subset=['Transaction_ID'], keep=False)]\ndup_count = len(duplicate_ids)\n\nif dup_count > 0:\n    print(f\"   Count: {dup_count:,} rows with duplicate IDs\")\n    print(f\"   Examples:\")\n    dup_examples = duplicate_ids['Transaction_ID'].value_counts().head(3)\n    for tid, cnt in dup_examples.items():\n        print(f\"      ID {tid}: appears {cnt} times\")\nelse:\n    print(\"   No duplicate Transaction IDs found\")\n\n# --- 3. Invalid Prices ---\nprint(\"\\n3Ô∏è‚É£ INVALID PRICES (negative or zero)\")\nprint(\"-\" * 30)\ninvalid_prices = df[df['Total_Cost'] <= 0]\ninv_price_count = len(invalid_prices)\n\nif inv_price_count > 0:\n    print(f\"   Count: {inv_price_count:,}\")\n    print(f\"   Examples:\")\n    for idx, row in invalid_prices.head(3).iterrows():\n        print(f\"      Row {idx}: ${row['Total_Cost']}\")\nelse:\n    print(\"   No invalid prices found\")\n\n# --- 4. Invalid Quantities ---\nprint(\"\\n4Ô∏è‚É£ INVALID QUANTITIES (zero or negative)\")\nprint(\"-\" * 30)\ninvalid_qty = df[df['Total_Items'] <= 0]\ninv_qty_count = len(invalid_qty)\n\nif inv_qty_count > 0:\n    print(f\"   Count: {inv_qty_count:,}\")\n    print(f\"   Examples:\")\n    for idx, row in invalid_qty.head(3).iterrows():\n        print(f\"      Row {idx}: {row['Total_Items']} items\")\nelse:\n    print(\"   No invalid quantities found\")\n\n# --- 5. Whitespace Issues ---\nprint(\"\\n5Ô∏è‚É£ WHITESPACE ISSUES (leading/trailing spaces)\")\nprint(\"-\" * 30)\nstring_cols = ['Customer_Name', 'Product', 'City', 'Promotion']\nwhitespace_issues = 0\n\nfor col in string_cols:\n    if col in df.columns:\n        # Check for leading/trailing whitespace\n        has_whitespace = df[col].astype(str).str.contains(r'^\\s+|\\s+$', regex=True, na=False)\n        count = has_whitespace.sum()\n        if count > 0:\n            whitespace_issues += count\n            example = df.loc[has_whitespace, col].iloc[0] if count > 0 else \"N/A\"\n            print(f\"   {col}: {count:,} rows\")\n            print(f\"      Example: '{example}'\")\n\nif whitespace_issues == 0:\n    print(\"   No whitespace issues found\")\n\n# --- Summary ---\nprint(\"\\n\" + \"=\" * 50)\nprint(\"SUMMARY\")\nprint(\"=\" * 50)\nprint(f\"   Total rows:              {len(df):,}\")\nprint(f\"   Missing values:          {total_missing:,}\")\nprint(f\"   Duplicate IDs:           {dup_count:,}\")\nprint(f\"   Invalid prices:          {inv_price_count:,}\")\nprint(f\"   Invalid quantities:      {inv_qty_count:,}\")\nprint(f\"   Whitespace issues:       {whitespace_issues:,}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Step 7: Cleaning Rules\n\nThe `clean()` method applies the following transformations:\n\n| Rule | Before | After |\n|------|--------|-------|\n| Strip whitespace | `\"  John  \"` | `\"John\"` |\n| Title case names | `\"john DOE\"` | `\"John Doe\"` |\n| Uppercase promos | `\"save20\"` | `\"SAVE20\"` |\n| Handle null strings | `None` | `None` (unchanged) |\n| Convert quantities | `\"5\"` or `NaN` | `5` or `0` |\n| Convert prices | `\"99.99\"` or `NaN` | `99.99` or `0.0` |\n\nBelow we demonstrate before/after comparisons on sample data.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ============================================\n# BEFORE/AFTER CLEANING COMPARISON\n# ============================================\n\n# Create sample dirty data to demonstrate cleaning\ndirty_samples = [\n    {\n        'Transaction_ID': 'TEST001',\n        'Date': '2024-01-15',\n        'Customer_Name': '  john DOE  ',      # whitespace + wrong case\n        'Product': 'LAPTOP computer',          # inconsistent case\n        'Total_Items': '3',                    # string instead of int\n        'Total_Cost': '999.99',                # string instead of float\n        'City': '  new york  ',                # whitespace + lowercase\n        'Promotion': 'save20'                  # lowercase promo code\n    },\n    {\n        'Transaction_ID': 'TEST002',\n        'Date': '2024-01-16',\n        'Customer_Name': 'JANE SMITH',         # all caps\n        'Product': '  wireless mouse  ',       # whitespace\n        'Total_Items': None,                   # missing value\n        'Total_Cost': None,                    # missing value\n        'City': 'LOS ANGELES',                 # all caps\n        'Promotion': '  PROMO50  '             # whitespace\n    },\n    {\n        'Transaction_ID': 'TEST003',\n        'Date': '2024-01-17',\n        'Customer_Name': 'bob wilson',         # all lowercase\n        'Product': 'USB Cable',                # mixed case (correct)\n        'Total_Items': 0,                      # zero quantity\n        'Total_Cost': -50.00,                  # negative price\n        'City': 'chicago',                     # lowercase\n        'Promotion': None                      # no promo\n    }\n]\n\nprint(\"=\" * 70)\nprint(\"BEFORE/AFTER CLEANING COMPARISON\")\nprint(\"=\" * 70)\n\nfor i, dirty_row in enumerate(dirty_samples, 1):\n    print(f\"\\n{'‚îÄ' * 70}\")\n    print(f\"SAMPLE {i}\")\n    print(f\"{'‚îÄ' * 70}\")\n    \n    # Create transaction WITHOUT cleaning\n    before = Transaction(dirty_row)\n    \n    # Create transaction WITH cleaning\n    after = Transaction(dirty_row)\n    after.clean()\n    \n    # Display comparison\n    print(f\"\\n{'Field':<15} {'BEFORE':<25} {'AFTER':<25}\")\n    print(f\"{'-' * 15} {'-' * 25} {'-' * 25}\")\n    \n    print(f\"{'customer_name':<15} {repr(before.customer_name):<25} {repr(after.customer_name):<25}\")\n    print(f\"{'product':<15} {repr(before.product):<25} {repr(after.product):<25}\")\n    print(f\"{'city':<15} {repr(before.city):<25} {repr(after.city):<25}\")\n    print(f\"{'promotion':<15} {repr(before.promotion):<25} {repr(after.promotion):<25}\")\n    print(f\"{'quantity':<15} {repr(before.quantity):<25} {repr(after.quantity):<25}\")\n    print(f\"{'price':<15} {repr(before.price):<25} {repr(after.price):<25}\")\n\nprint(f\"\\n{'=' * 70}\")\nprint(\"CLEANING RULES APPLIED:\")\nprint(\"=\" * 70)\nprint(\"  1. strip()    - Remove leading/trailing whitespace\")\nprint(\"  2. title()    - Convert to Title Case (names, products, cities)\")\nprint(\"  3. upper()    - Convert to UPPERCASE (promotion codes)\")\nprint(\"  4. int()      - Convert quantity to integer, default to 0\")\nprint(\"  5. float()    - Convert price to float, default to 0.0\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Step 8: Transform Coupon Codes\n\nExtract discount values from promotion codes using regular expressions:\n\n| Promotion Code | Extracted Discount |\n|----------------|-------------------|\n| `SAVE20` | `20` |\n| `PROMO50` | `50` |\n| `DISCOUNT15OFF` | `15` |\n| `FREESHIP` | `0` (no numeric value) |\n| `None` | `0` |\n\n**Regex pattern**: `\\d+` matches one or more digits in the promotion string.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import re\n\ndef extract_discount(promotion):\n    \"\"\"\n    Extract numeric discount value from a promotion code using regex.\n    \n    Args:\n        promotion: Promotion code string (e.g., 'SAVE20', 'PROMO50')\n    \n    Returns:\n        int: Extracted discount value, or 0 if no number found\n    \"\"\"\n    if promotion is None:\n        return 0\n    \n    # Convert to string in case of non-string input\n    promo_str = str(promotion)\n    \n    # Regex pattern: match one or more digits\n    match = re.search(r'\\d+', promo_str)\n    \n    if match:\n        return int(match.group())\n    return 0\n\n\n# ============================================\n# DEMONSTRATE DISCOUNT EXTRACTION\n# ============================================\n\nprint(\"=\" * 60)\nprint(\"COUPON CODE TRANSFORMATION\")\nprint(\"=\" * 60)\n\n# Test cases\ntest_promotions = [\n    'SAVE20',\n    'PROMO50',\n    'DISCOUNT15OFF',\n    'GET10PCT',\n    'FREESHIP',\n    'SUMMER2024SALE25',\n    None,\n    ''\n]\n\nprint(f\"\\n{'Promotion Code':<25} {'Extracted Discount':<20}\")\nprint(f\"{'-' * 25} {'-' * 20}\")\n\nfor promo in test_promotions:\n    discount = extract_discount(promo)\n    promo_display = repr(promo) if promo is not None else 'None'\n    print(f\"{promo_display:<25} {discount}%\")\n\n# ============================================\n# APPLY TO ALL TRANSACTIONS\n# ============================================\n\nprint(f\"\\n{'=' * 60}\")\nprint(\"APPLYING TO DATASET\")\nprint(\"=\" * 60)\n\n# Extract discounts for all transactions\ndiscounts = [extract_discount(t.promotion) for t in transactions]\n\n# Count transactions with discounts\nwith_discount = sum(1 for d in discounts if d > 0)\nwithout_discount = len(discounts) - with_discount\n\nprint(f\"\\nüìä Discount Statistics:\")\nprint(f\"   Transactions with discount:    {with_discount:,}\")\nprint(f\"   Transactions without discount: {without_discount:,}\")\n\n# Show discount distribution\ndiscount_counts = {}\nfor d in discounts:\n    discount_counts[d] = discount_counts.get(d, 0) + 1\n\nprint(f\"\\nüìà Discount Distribution (top 5):\")\nfor discount, count in sorted(discount_counts.items(), key=lambda x: -x[1])[:5]:\n    pct = (count / len(discounts)) * 100\n    print(f\"   {discount}% discount: {count:,} transactions ({pct:.1f}%)\")\n\n# Show sample transactions with extracted discounts\nprint(f\"\\nüìã Sample Transactions with Discounts:\")\nprint(f\"{'Promotion':<20} {'Discount':<10} {'Price':<15}\")\nprint(f\"{'-' * 20} {'-' * 10} {'-' * 15}\")\n\nsample_count = 0\nfor t in transactions:\n    discount = extract_discount(t.promotion)\n    if discount > 0 and sample_count < 5:\n        print(f\"{str(t.promotion):<20} {discount}%{'':<8} ${t.price:,.2f}\")\n        sample_count += 1",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}