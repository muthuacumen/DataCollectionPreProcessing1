{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 01: Data Collection and Preprocessing\n",
    "\n",
    "This notebook demonstrates fundamental data collection and preprocessing techniques using Python and pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Load the Dataset\n",
    "\n",
    "In this step, we load the retail transactions CSV file using pandas and inspect the first few rows to understand the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import pandas library\nimport pandas as pd\n\n# Load the CSV file into a DataFrame\ndf = pd.read_csv('data/Retail_Transactions_Dataset.csv')\n\n# Display the first 3 rows\ndf.head(3)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Data Structure Choice\n",
    "\n",
    "### Why pandas DataFrame?\n",
    "\n",
    "We use a **pandas DataFrame** to store our retail transactions data for the following reasons:\n",
    "\n",
    "| Criteria | DataFrame Advantage |\n",
    "|----------|---------------------|\n",
    "| **Tabular format** | CSV data is naturally row-column structured; DataFrames mirror this exactly |\n",
    "| **Mixed data types** | Our dataset contains strings (`Product`, `City`), numbers (`Total_Cost`, `Total_Items`), and dates (`Date`) ‚Äî DataFrames handle heterogeneous columns efficiently |\n",
    "| **Built-in methods** | Pandas provides optimized functions for filtering, grouping, aggregating, and cleaning data |\n",
    "| **Memory efficiency** | DataFrames use NumPy arrays under the hood, enabling vectorized operations |\n",
    "| **Ecosystem integration** | Seamless compatibility with visualization libraries (matplotlib, seaborn) and ML frameworks (scikit-learn) |\n",
    "\n",
    "### Alternatives Considered\n",
    "\n",
    "- **Python lists/dicts**: No built-in support for column operations or missing data handling\n",
    "- **NumPy arrays**: Require homogeneous data types; not ideal for mixed-type tabular data\n",
    "- **SQL database**: Overkill for a single-file analysis; adds setup complexity\n",
    "\n",
    "**Conclusion**: pandas DataFrame is the optimal choice for exploratory data analysis and preprocessing of structured CSV data."
   ]
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Step 3: Transaction Class\n\nWe define a `Transaction` class to encapsulate individual transaction records. This provides:\n- **Encapsulation**: Each transaction is a self-contained object\n- **Data cleaning**: The `clean()` method standardizes and sanitizes field values\n- **Calculations**: The `total()` method computes the transaction total",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class Transaction:\n    \"\"\"\n    Represents a single retail transaction.\n    \n    Attributes:\n        transaction_id: Unique identifier for the transaction\n        date: Date of the transaction\n        customer_name: Name of the customer\n        product: Product purchased\n        quantity: Number of items (Total_Items)\n        price: Cost of the transaction (Total_Cost)\n        city: City where the transaction occurred\n        promotion: Promotion/coupon code applied\n    \"\"\"\n    \n    def __init__(self, row):\n        \"\"\"Initialize a Transaction from a DataFrame row.\"\"\"\n        self.transaction_id = row.get('Transaction_ID', None)\n        self.date = row.get('Date', None)\n        self.customer_name = row.get('Customer_Name', None)\n        self.product = row.get('Product', None)\n        self.quantity = row.get('Total_Items', 0)\n        self.price = row.get('Total_Cost', 0.0)\n        self.city = row.get('City', None)\n        self.promotion = row.get('Promotion', None)\n    \n    def clean(self):\n        \"\"\"\n        Clean and standardize transaction data.\n        \n        Returns:\n            self: The Transaction instance (for method chaining)\n        \"\"\"\n        # Strip whitespace from string fields\n        if isinstance(self.customer_name, str):\n            self.customer_name = self.customer_name.strip().title()\n        \n        if isinstance(self.product, str):\n            self.product = self.product.strip().title()\n        \n        if isinstance(self.city, str):\n            self.city = self.city.strip().title()\n        \n        if isinstance(self.promotion, str):\n            self.promotion = self.promotion.strip().upper()\n        \n        # Handle missing/invalid numeric values\n        try:\n            self.quantity = int(self.quantity) if self.quantity else 0\n        except (ValueError, TypeError):\n            self.quantity = 0\n        \n        try:\n            self.price = float(self.price) if self.price else 0.0\n        except (ValueError, TypeError):\n            self.price = 0.0\n        \n        return self\n    \n    def total(self):\n        \"\"\"\n        Calculate the transaction total.\n        \n        Returns:\n            float: The total cost of the transaction\n        \"\"\"\n        return float(self.price)\n    \n    def __repr__(self):\n        \"\"\"String representation for debugging.\"\"\"\n        return f\"Transaction(id={self.transaction_id}, product={self.product}, total={self.total():.2f})\"\n\n\n# --- Demo: Create and clean a Transaction ---\n# Get the first row as a dictionary\nsample_row = df.iloc[0].to_dict()\n\n# Create a Transaction object\ntxn = Transaction(sample_row)\n\n# Clean the transaction data\ntxn.clean()\n\n# Display the transaction\nprint(f\"Transaction ID: {txn.transaction_id}\")\nprint(f\"Customer:       {txn.customer_name}\")\nprint(f\"Product:        {txn.product}\")\nprint(f\"Quantity:       {txn.quantity}\")\nprint(f\"City:           {txn.city}\")\nprint(f\"Promotion:      {txn.promotion}\")\nprint(f\"Total:          ${txn.total():.2f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Step 4: Bulk Load Transactions\n\nConvert the entire DataFrame into a list of `Transaction` objects. This demonstrates:\n- Iterating over DataFrame rows\n- Creating objects in bulk\n- Applying the `clean()` method to each transaction",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Convert DataFrame rows to a list of Transaction objects\n# Each row becomes a Transaction, then we call clean() on it\n\ntransactions = []\n\nfor index, row in df.iterrows():\n    # Convert row to dictionary and create Transaction\n    txn = Transaction(row.to_dict())\n    \n    # Clean the transaction data\n    txn.clean()\n    \n    # Add to list\n    transactions.append(txn)\n\n# Display summary\nprint(f\"Total transactions loaded: {len(transactions):,}\")\nprint(f\"\\nFirst 3 transactions:\")\nfor t in transactions[:3]:\n    print(f\"  {t}\")\n\nprint(f\"\\nLast 3 transactions:\")\nfor t in transactions[-3:]:\n    print(f\"  {t}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Step 5: Data Profiling\n\nCompute basic statistics to understand the dataset:\n- **Price statistics**: min, mean, max\n- **Unique cities**: count of distinct shipping locations",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Extract prices from all transactions\nprices = [t.price for t in transactions]\n\n# Compute price statistics\nmin_price = min(prices)\nmax_price = max(prices)\nmean_price = sum(prices) / len(prices)\n\n# Get unique cities\ncities = set(t.city for t in transactions)\nunique_city_count = len(cities)\n\n# Display profiling results\nprint(\"=\" * 40)\nprint(\"DATA PROFILING RESULTS\")\nprint(\"=\" * 40)\n\nprint(f\"\\nüìä Price Statistics:\")\nprint(f\"   Min:  ${min_price:,.2f}\")\nprint(f\"   Mean: ${mean_price:,.2f}\")\nprint(f\"   Max:  ${max_price:,.2f}\")\n\nprint(f\"\\nüèôÔ∏è City Statistics:\")\nprint(f\"   Unique cities: {unique_city_count}\")\n\nprint(f\"\\nüìã Sample cities:\")\nfor city in sorted(cities)[:5]:\n    print(f\"   - {city}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Step 6: Identify Dirty Data\n\nBefore cleaning, we analyze the raw DataFrame to identify data quality issues:\n- **Missing values**: Null or NaN entries\n- **Duplicates**: Repeated transaction IDs\n- **Invalid values**: Negative prices, zero quantities\n- **Inconsistent formatting**: Mixed case, extra whitespace",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ============================================\n# DIRTY DATA IDENTIFICATION\n# ============================================\n\nprint(\"=\" * 50)\nprint(\"DIRTY DATA REPORT\")\nprint(\"=\" * 50)\n\n# --- 1. Missing Values ---\nprint(\"\\n1Ô∏è‚É£ MISSING VALUES\")\nprint(\"-\" * 30)\nmissing_counts = df.isnull().sum()\ntotal_missing = missing_counts.sum()\n\nif total_missing > 0:\n    for col, count in missing_counts.items():\n        if count > 0:\n            pct = (count / len(df)) * 100\n            print(f\"   {col}: {count:,} ({pct:.2f}%)\")\nelse:\n    print(\"   No missing values found\")\n\n# --- 2. Duplicate Transaction IDs ---\nprint(\"\\n2Ô∏è‚É£ DUPLICATE TRANSACTION IDs\")\nprint(\"-\" * 30)\nduplicate_ids = df[df.duplicated(subset=['Transaction_ID'], keep=False)]\ndup_count = len(duplicate_ids)\n\nif dup_count > 0:\n    print(f\"   Count: {dup_count:,} rows with duplicate IDs\")\n    print(f\"   Examples:\")\n    dup_examples = duplicate_ids['Transaction_ID'].value_counts().head(3)\n    for tid, cnt in dup_examples.items():\n        print(f\"      ID {tid}: appears {cnt} times\")\nelse:\n    print(\"   No duplicate Transaction IDs found\")\n\n# --- 3. Invalid Prices ---\nprint(\"\\n3Ô∏è‚É£ INVALID PRICES (negative or zero)\")\nprint(\"-\" * 30)\ninvalid_prices = df[df['Total_Cost'] <= 0]\ninv_price_count = len(invalid_prices)\n\nif inv_price_count > 0:\n    print(f\"   Count: {inv_price_count:,}\")\n    print(f\"   Examples:\")\n    for idx, row in invalid_prices.head(3).iterrows():\n        print(f\"      Row {idx}: ${row['Total_Cost']}\")\nelse:\n    print(\"   No invalid prices found\")\n\n# --- 4. Invalid Quantities ---\nprint(\"\\n4Ô∏è‚É£ INVALID QUANTITIES (zero or negative)\")\nprint(\"-\" * 30)\ninvalid_qty = df[df['Total_Items'] <= 0]\ninv_qty_count = len(invalid_qty)\n\nif inv_qty_count > 0:\n    print(f\"   Count: {inv_qty_count:,}\")\n    print(f\"   Examples:\")\n    for idx, row in invalid_qty.head(3).iterrows():\n        print(f\"      Row {idx}: {row['Total_Items']} items\")\nelse:\n    print(\"   No invalid quantities found\")\n\n# --- 5. Whitespace Issues ---\nprint(\"\\n5Ô∏è‚É£ WHITESPACE ISSUES (leading/trailing spaces)\")\nprint(\"-\" * 30)\nstring_cols = ['Customer_Name', 'Product', 'City', 'Promotion']\nwhitespace_issues = 0\n\nfor col in string_cols:\n    if col in df.columns:\n        # Check for leading/trailing whitespace\n        has_whitespace = df[col].astype(str).str.contains(r'^\\s+|\\s+$', regex=True, na=False)\n        count = has_whitespace.sum()\n        if count > 0:\n            whitespace_issues += count\n            example = df.loc[has_whitespace, col].iloc[0] if count > 0 else \"N/A\"\n            print(f\"   {col}: {count:,} rows\")\n            print(f\"      Example: '{example}'\")\n\nif whitespace_issues == 0:\n    print(\"   No whitespace issues found\")\n\n# --- Summary ---\nprint(\"\\n\" + \"=\" * 50)\nprint(\"SUMMARY\")\nprint(\"=\" * 50)\nprint(f\"   Total rows:              {len(df):,}\")\nprint(f\"   Missing values:          {total_missing:,}\")\nprint(f\"   Duplicate IDs:           {dup_count:,}\")\nprint(f\"   Invalid prices:          {inv_price_count:,}\")\nprint(f\"   Invalid quantities:      {inv_qty_count:,}\")\nprint(f\"   Whitespace issues:       {whitespace_issues:,}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Step 7: Cleaning Rules\n\nThe `clean()` method applies the following transformations:\n\n| Rule | Before | After |\n|------|--------|-------|\n| Strip whitespace | `\"  John  \"` | `\"John\"` |\n| Title case names | `\"john DOE\"` | `\"John Doe\"` |\n| Uppercase promos | `\"save20\"` | `\"SAVE20\"` |\n| Handle null strings | `None` | `None` (unchanged) |\n| Convert quantities | `\"5\"` or `NaN` | `5` or `0` |\n| Convert prices | `\"99.99\"` or `NaN` | `99.99` or `0.0` |\n\nBelow we demonstrate before/after comparisons on sample data.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ============================================\n# BEFORE/AFTER CLEANING COMPARISON\n# ============================================\n\n# Create sample dirty data to demonstrate cleaning\ndirty_samples = [\n    {\n        'Transaction_ID': 'TEST001',\n        'Date': '2024-01-15',\n        'Customer_Name': '  john DOE  ',      # whitespace + wrong case\n        'Product': 'LAPTOP computer',          # inconsistent case\n        'Total_Items': '3',                    # string instead of int\n        'Total_Cost': '999.99',                # string instead of float\n        'City': '  new york  ',                # whitespace + lowercase\n        'Promotion': 'save20'                  # lowercase promo code\n    },\n    {\n        'Transaction_ID': 'TEST002',\n        'Date': '2024-01-16',\n        'Customer_Name': 'JANE SMITH',         # all caps\n        'Product': '  wireless mouse  ',       # whitespace\n        'Total_Items': None,                   # missing value\n        'Total_Cost': None,                    # missing value\n        'City': 'LOS ANGELES',                 # all caps\n        'Promotion': '  PROMO50  '             # whitespace\n    },\n    {\n        'Transaction_ID': 'TEST003',\n        'Date': '2024-01-17',\n        'Customer_Name': 'bob wilson',         # all lowercase\n        'Product': 'USB Cable',                # mixed case (correct)\n        'Total_Items': 0,                      # zero quantity\n        'Total_Cost': -50.00,                  # negative price\n        'City': 'chicago',                     # lowercase\n        'Promotion': None                      # no promo\n    }\n]\n\nprint(\"=\" * 70)\nprint(\"BEFORE/AFTER CLEANING COMPARISON\")\nprint(\"=\" * 70)\n\nfor i, dirty_row in enumerate(dirty_samples, 1):\n    print(f\"\\n{'‚îÄ' * 70}\")\n    print(f\"SAMPLE {i}\")\n    print(f\"{'‚îÄ' * 70}\")\n    \n    # Create transaction WITHOUT cleaning\n    before = Transaction(dirty_row)\n    \n    # Create transaction WITH cleaning\n    after = Transaction(dirty_row)\n    after.clean()\n    \n    # Display comparison\n    print(f\"\\n{'Field':<15} {'BEFORE':<25} {'AFTER':<25}\")\n    print(f\"{'-' * 15} {'-' * 25} {'-' * 25}\")\n    \n    print(f\"{'customer_name':<15} {repr(before.customer_name):<25} {repr(after.customer_name):<25}\")\n    print(f\"{'product':<15} {repr(before.product):<25} {repr(after.product):<25}\")\n    print(f\"{'city':<15} {repr(before.city):<25} {repr(after.city):<25}\")\n    print(f\"{'promotion':<15} {repr(before.promotion):<25} {repr(after.promotion):<25}\")\n    print(f\"{'quantity':<15} {repr(before.quantity):<25} {repr(after.quantity):<25}\")\n    print(f\"{'price':<15} {repr(before.price):<25} {repr(after.price):<25}\")\n\nprint(f\"\\n{'=' * 70}\")\nprint(\"CLEANING RULES APPLIED:\")\nprint(\"=\" * 70)\nprint(\"  1. strip()    - Remove leading/trailing whitespace\")\nprint(\"  2. title()    - Convert to Title Case (names, products, cities)\")\nprint(\"  3. upper()    - Convert to UPPERCASE (promotion codes)\")\nprint(\"  4. int()      - Convert quantity to integer, default to 0\")\nprint(\"  5. float()    - Convert price to float, default to 0.0\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Step 8: Transform Coupon Codes\n\nExtract discount values from promotion codes using regular expressions:\n\n| Promotion Code | Extracted Discount |\n|----------------|-------------------|\n| `SAVE20` | `20` |\n| `PROMO50` | `50` |\n| `DISCOUNT15OFF` | `15` |\n| `FREESHIP` | `0` (no numeric value) |\n| `None` | `0` |\n\n**Regex pattern**: `\\d+` matches one or more digits in the promotion string.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import re\n\ndef extract_discount(promotion):\n    \"\"\"\n    Extract numeric discount value from a promotion code using regex.\n    \n    Args:\n        promotion: Promotion code string (e.g., 'SAVE20', 'PROMO50')\n    \n    Returns:\n        int: Extracted discount value, or 0 if no number found\n    \"\"\"\n    if promotion is None:\n        return 0\n    \n    # Convert to string in case of non-string input\n    promo_str = str(promotion)\n    \n    # Regex pattern: match one or more digits\n    match = re.search(r'\\d+', promo_str)\n    \n    if match:\n        return int(match.group())\n    return 0\n\n\n# ============================================\n# DEMONSTRATE DISCOUNT EXTRACTION\n# ============================================\n\nprint(\"=\" * 60)\nprint(\"COUPON CODE TRANSFORMATION\")\nprint(\"=\" * 60)\n\n# Test cases\ntest_promotions = [\n    'SAVE20',\n    'PROMO50',\n    'DISCOUNT15OFF',\n    'GET10PCT',\n    'FREESHIP',\n    'SUMMER2024SALE25',\n    None,\n    ''\n]\n\nprint(f\"\\n{'Promotion Code':<25} {'Extracted Discount':<20}\")\nprint(f\"{'-' * 25} {'-' * 20}\")\n\nfor promo in test_promotions:\n    discount = extract_discount(promo)\n    promo_display = repr(promo) if promo is not None else 'None'\n    print(f\"{promo_display:<25} {discount}%\")\n\n# ============================================\n# APPLY TO ALL TRANSACTIONS\n# ============================================\n\nprint(f\"\\n{'=' * 60}\")\nprint(\"APPLYING TO DATASET\")\nprint(\"=\" * 60)\n\n# Extract discounts for all transactions\ndiscounts = [extract_discount(t.promotion) for t in transactions]\n\n# Count transactions with discounts\nwith_discount = sum(1 for d in discounts if d > 0)\nwithout_discount = len(discounts) - with_discount\n\nprint(f\"\\nüìä Discount Statistics:\")\nprint(f\"   Transactions with discount:    {with_discount:,}\")\nprint(f\"   Transactions without discount: {without_discount:,}\")\n\n# Show discount distribution\ndiscount_counts = {}\nfor d in discounts:\n    discount_counts[d] = discount_counts.get(d, 0) + 1\n\nprint(f\"\\nüìà Discount Distribution (top 5):\")\nfor discount, count in sorted(discount_counts.items(), key=lambda x: -x[1])[:5]:\n    pct = (count / len(discounts)) * 100\n    print(f\"   {discount}% discount: {count:,} transactions ({pct:.1f}%)\")\n\n# Show sample transactions with extracted discounts\nprint(f\"\\nüìã Sample Transactions with Discounts:\")\nprint(f\"{'Promotion':<20} {'Discount':<10} {'Price':<15}\")\nprint(f\"{'-' * 20} {'-' * 10} {'-' * 15}\")\n\nsample_count = 0\nfor t in transactions:\n    discount = extract_discount(t.promotion)\n    if discount > 0 and sample_count < 5:\n        print(f\"{str(t.promotion):<20} {discount}%{'':<8} ${t.price:,.2f}\")\n        sample_count += 1",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Step 9: Feature Engineering\n\nAdd a computed property `days_since_purchase` using Python's `datetime` module and the `@property` decorator.\n\n**Benefits of `@property`:**\n- Computed on-demand (not stored)\n- Accessed like an attribute: `txn.days_since_purchase`\n- Encapsulates date parsing logic\n- Always returns current value relative to today",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from datetime import datetime, date\n\nclass TransactionWithFeatures(Transaction):\n    \"\"\"\n    Extended Transaction class with feature engineering.\n    \n    Inherits from Transaction and adds computed properties.\n    \"\"\"\n    \n    @property\n    def days_since_purchase(self):\n        \"\"\"\n        Calculate the number of days since the purchase date.\n        \n        Returns:\n            int: Days between purchase date and today, or -1 if date is invalid\n        \"\"\"\n        if self.date is None:\n            return -1\n        \n        try:\n            # Parse the date string (handles multiple formats)\n            if isinstance(self.date, str):\n                # Try common date formats\n                for fmt in ['%Y-%m-%d', '%m/%d/%Y', '%d/%m/%Y', '%Y/%m/%d']:\n                    try:\n                        purchase_date = datetime.strptime(self.date, fmt).date()\n                        break\n                    except ValueError:\n                        continue\n                else:\n                    # No format matched\n                    return -1\n            elif isinstance(self.date, (datetime, date)):\n                purchase_date = self.date if isinstance(self.date, date) else self.date.date()\n            else:\n                return -1\n            \n            # Calculate difference from today\n            today = date.today()\n            delta = today - purchase_date\n            return delta.days\n            \n        except (ValueError, TypeError):\n            return -1\n    \n    @property\n    def discount_amount(self):\n        \"\"\"\n        Calculate the discount amount based on promotion code.\n        \n        Returns:\n            float: Discount amount in dollars\n        \"\"\"\n        discount_pct = extract_discount(self.promotion)\n        return (discount_pct / 100) * self.price\n\n\n# ============================================\n# DEMONSTRATE FEATURE ENGINEERING\n# ============================================\n\nprint(\"=\" * 60)\nprint(\"FEATURE ENGINEERING: days_since_purchase\")\nprint(\"=\" * 60)\n\n# Test with sample dates\ntest_rows = [\n    {'Transaction_ID': 'T001', 'Date': '2024-01-15', 'Product': 'Laptop', \n     'Total_Cost': 999.99, 'Total_Items': 1, 'Promotion': 'SAVE10'},\n    {'Transaction_ID': 'T002', 'Date': '2025-01-01', 'Product': 'Phone', \n     'Total_Cost': 599.99, 'Total_Items': 1, 'Promotion': 'PROMO20'},\n    {'Transaction_ID': 'T003', 'Date': '2025-12-25', 'Product': 'Tablet', \n     'Total_Cost': 399.99, 'Total_Items': 2, 'Promotion': None},\n    {'Transaction_ID': 'T004', 'Date': None, 'Product': 'Cable', \n     'Total_Cost': 19.99, 'Total_Items': 3, 'Promotion': 'SAVE5'},\n]\n\nprint(f\"\\n{'Date':<15} {'Days Since':<12} {'Product':<15} {'Discount Amt':<12}\")\nprint(f\"{'-' * 15} {'-' * 12} {'-' * 15} {'-' * 12}\")\n\nfor row in test_rows:\n    txn = TransactionWithFeatures(row)\n    txn.clean()\n    days = txn.days_since_purchase\n    days_str = str(days) if days >= 0 else \"Invalid\"\n    discount_amt = txn.discount_amount\n    print(f\"{str(row['Date']):<15} {days_str:<12} {txn.product:<15} ${discount_amt:,.2f}\")\n\n# ============================================\n# APPLY TO REAL TRANSACTIONS\n# ============================================\n\nprint(f\"\\n{'=' * 60}\")\nprint(\"APPLYING TO DATASET\")\nprint(\"=\" * 60)\n\n# Convert existing transactions to TransactionWithFeatures\nenhanced_transactions = []\nfor t in transactions[:1000]:  # Sample first 1000 for demo\n    row = {\n        'Transaction_ID': t.transaction_id,\n        'Date': t.date,\n        'Customer_Name': t.customer_name,\n        'Product': t.product,\n        'Total_Items': t.quantity,\n        'Total_Cost': t.price,\n        'City': t.city,\n        'Promotion': t.promotion\n    }\n    enhanced = TransactionWithFeatures(row)\n    enhanced.clean()\n    enhanced_transactions.append(enhanced)\n\n# Calculate statistics on days_since_purchase\nvalid_days = [t.days_since_purchase for t in enhanced_transactions if t.days_since_purchase >= 0]\n\nif valid_days:\n    print(f\"\\nüìä Days Since Purchase Statistics (sample of 1,000):\")\n    print(f\"   Min:  {min(valid_days):,} days\")\n    print(f\"   Max:  {max(valid_days):,} days\")\n    print(f\"   Mean: {sum(valid_days) / len(valid_days):,.1f} days\")\n    print(f\"   Valid dates: {len(valid_days):,}\")\n    print(f\"   Invalid dates: {len(enhanced_transactions) - len(valid_days):,}\")\n\n# Show sample enhanced transactions\nprint(f\"\\nüìã Sample Enhanced Transactions:\")\nprint(f\"{'ID':<10} {'Date':<12} {'Days Ago':<10} {'Product':<20}\")\nprint(f\"{'-' * 10} {'-' * 12} {'-' * 10} {'-' * 20}\")\n\nfor t in enhanced_transactions[:5]:\n    days = t.days_since_purchase\n    days_str = str(days) if days >= 0 else \"N/A\"\n    print(f\"{str(t.transaction_id):<10} {str(t.date):<12} {days_str:<10} {str(t.product)[:20]:<20}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Step 10: Aggregation\n\nAggregate total revenue by shipping city to identify top-performing markets.\n\n**Aggregation approach:**\n1. Group transactions by `city`\n2. Sum `price` (revenue) for each city\n3. Count transactions per city\n4. Sort by revenue descending",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ============================================\n# REVENUE AGGREGATION BY CITY\n# ============================================\n\ndef aggregate_revenue_by_city(transactions):\n    \"\"\"\n    Aggregate total revenue and transaction count by shipping city.\n    \n    Args:\n        transactions: List of Transaction objects\n    \n    Returns:\n        dict: {city: {'revenue': float, 'count': int, 'avg_order': float}}\n    \"\"\"\n    city_stats = {}\n    \n    for t in transactions:\n        city = t.city if t.city else 'Unknown'\n        \n        if city not in city_stats:\n            city_stats[city] = {'revenue': 0.0, 'count': 0}\n        \n        city_stats[city]['revenue'] += t.price\n        city_stats[city]['count'] += 1\n    \n    # Calculate average order value for each city\n    for city in city_stats:\n        count = city_stats[city]['count']\n        revenue = city_stats[city]['revenue']\n        city_stats[city]['avg_order'] = revenue / count if count > 0 else 0\n    \n    return city_stats\n\n\n# Aggregate revenue by city\ncity_revenue = aggregate_revenue_by_city(transactions)\n\n# Sort by revenue (descending)\nsorted_cities = sorted(city_revenue.items(), key=lambda x: x[1]['revenue'], reverse=True)\n\n# Calculate totals\ntotal_revenue = sum(stats['revenue'] for _, stats in sorted_cities)\ntotal_transactions = sum(stats['count'] for _, stats in sorted_cities)\n\nprint(\"=\" * 70)\nprint(\"REVENUE AGGREGATION BY SHIPPING CITY\")\nprint(\"=\" * 70)\n\nprint(f\"\\nüìä Overall Statistics:\")\nprint(f\"   Total Revenue:      ${total_revenue:,.2f}\")\nprint(f\"   Total Transactions: {total_transactions:,}\")\nprint(f\"   Unique Cities:      {len(city_revenue):,}\")\n\n# Top 10 cities by revenue\nprint(f\"\\nüèÜ TOP 10 CITIES BY REVENUE\")\nprint(f\"{'-' * 70}\")\nprint(f\"{'Rank':<6} {'City':<20} {'Revenue':<18} {'Transactions':<14} {'Avg Order':<12}\")\nprint(f\"{'-' * 6} {'-' * 20} {'-' * 18} {'-' * 14} {'-' * 12}\")\n\nfor rank, (city, stats) in enumerate(sorted_cities[:10], 1):\n    revenue = stats['revenue']\n    count = stats['count']\n    avg = stats['avg_order']\n    pct = (revenue / total_revenue) * 100\n    print(f\"{rank:<6} {city[:20]:<20} ${revenue:>14,.2f} {count:>14,} ${avg:>10,.2f}\")\n\n# Bottom 5 cities by revenue\nprint(f\"\\nüìâ BOTTOM 5 CITIES BY REVENUE\")\nprint(f\"{'-' * 70}\")\nprint(f\"{'Rank':<6} {'City':<20} {'Revenue':<18} {'Transactions':<14} {'Avg Order':<12}\")\nprint(f\"{'-' * 6} {'-' * 20} {'-' * 18} {'-' * 14} {'-' * 12}\")\n\nfor rank, (city, stats) in enumerate(sorted_cities[-5:], len(sorted_cities) - 4):\n    revenue = stats['revenue']\n    count = stats['count']\n    avg = stats['avg_order']\n    print(f\"{rank:<6} {city[:20]:<20} ${revenue:>14,.2f} {count:>14,} ${avg:>10,.2f}\")\n\n# Revenue distribution summary\nprint(f\"\\nüìà REVENUE DISTRIBUTION\")\nprint(f\"{'-' * 70}\")\n\n# Calculate concentration\ntop_5_revenue = sum(stats['revenue'] for _, stats in sorted_cities[:5])\ntop_10_revenue = sum(stats['revenue'] for _, stats in sorted_cities[:10])\n\nprint(f\"   Top 5 cities:  ${top_5_revenue:>14,.2f} ({(top_5_revenue/total_revenue)*100:.1f}% of total)\")\nprint(f\"   Top 10 cities: ${top_10_revenue:>14,.2f} ({(top_10_revenue/total_revenue)*100:.1f}% of total)\")\nprint(f\"   Remaining:     ${total_revenue - top_10_revenue:>14,.2f} ({((total_revenue - top_10_revenue)/total_revenue)*100:.1f}% of total)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Step 11: Serialization\n\nSave the cleaned transaction data to multiple formats for downstream use:\n\n| Format | File | Use Case |\n|--------|------|----------|\n| **CSV** | `cleaned_transactions.csv` | Spreadsheet analysis, SQL import |\n| **JSON** | `cleaned_transactions.json` | Web APIs, NoSQL databases |",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import json\nimport csv\n\n# ============================================\n# SAVE CLEANED DATA TO CSV AND JSON\n# ============================================\n\ndef transaction_to_dict(t):\n    \"\"\"Convert a Transaction object to a dictionary.\"\"\"\n    return {\n        'transaction_id': t.transaction_id,\n        'date': t.date,\n        'customer_name': t.customer_name,\n        'product': t.product,\n        'quantity': t.quantity,\n        'price': t.price,\n        'city': t.city,\n        'promotion': t.promotion,\n        'discount_pct': extract_discount(t.promotion)\n    }\n\n# Convert all transactions to dictionaries\ncleaned_data = [transaction_to_dict(t) for t in transactions]\n\n# --- Save to CSV ---\ncsv_path = 'data/cleaned_transactions.csv'\nfieldnames = ['transaction_id', 'date', 'customer_name', 'product', \n              'quantity', 'price', 'city', 'promotion', 'discount_pct']\n\nwith open(csv_path, 'w', newline='', encoding='utf-8') as f:\n    writer = csv.DictWriter(f, fieldnames=fieldnames)\n    writer.writeheader()\n    writer.writerows(cleaned_data)\n\n# --- Save to JSON ---\njson_path = 'data/cleaned_transactions.json'\n\nwith open(json_path, 'w', encoding='utf-8') as f:\n    json.dump(cleaned_data, f, indent=2, ensure_ascii=False)\n\n# --- Verify files ---\nimport os\n\ncsv_size = os.path.getsize(csv_path)\njson_size = os.path.getsize(json_path)\n\nprint(\"=\" * 60)\nprint(\"SERIALIZATION COMPLETE\")\nprint(\"=\" * 60)\n\nprint(f\"\\nüìÅ Files Created:\")\nprint(f\"   CSV:  {csv_path}\")\nprint(f\"         Size: {csv_size:,} bytes ({csv_size/1024/1024:.2f} MB)\")\nprint(f\"   JSON: {json_path}\")\nprint(f\"         Size: {json_size:,} bytes ({json_size/1024/1024:.2f} MB)\")\n\nprint(f\"\\nüìä Records Written: {len(cleaned_data):,}\")\n\n# Preview CSV content\nprint(f\"\\nüìã CSV Preview (first 3 rows):\")\nprint(f\"{'-' * 60}\")\nwith open(csv_path, 'r', encoding='utf-8') as f:\n    for i, line in enumerate(f):\n        if i < 4:  # header + 3 rows\n            print(line.strip()[:80] + \"...\" if len(line) > 80 else line.strip())\n\n# Preview JSON content\nprint(f\"\\nüìã JSON Preview (first record):\")\nprint(f\"{'-' * 60}\")\nprint(json.dumps(cleaned_data[0], indent=2))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Step 12: Reflection\n\n### Functions vs Methods\n\nIn this lab, we used both **functions** and **methods** to process data:\n\n| Type | Example | Key Difference |\n|------|---------|----------------|\n| **Function** | `extract_discount(promo)` | Standalone, takes data as arguments |\n| **Method** | `txn.clean()` | Bound to an object, operates on `self` |\n\n**Why this matters:** Methods encapsulate behavior with data‚Äîthe `Transaction` class bundles attributes (`price`, `city`) with operations (`clean()`, `total()`). This promotes reusability and maintainability. Functions like `aggregate_revenue_by_city()` remain independent when they operate on collections rather than single objects.\n\n**Key takeaway:** Use methods for object-specific behavior; use functions for general-purpose transformations.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Data Dictionary\n\n### Primary Dataset: `Retail_Transactions_Dataset.csv`\n\n| Column | Data Type | Description | Example |\n|--------|-----------|-------------|---------|\n| `Transaction_ID` | string | Unique identifier for each transaction | `TXN001` |\n| `Date` | string | Date of purchase (YYYY-MM-DD) | `2024-01-15` |\n| `Customer_Name` | string | Full name of the customer | `John Doe` |\n| `Product` | string | Name of the product purchased | `Laptop` |\n| `Total_Items` | integer | Quantity of items purchased | `3` |\n| `Total_Cost` | float | Total transaction amount in USD | `299.99` |\n| `Payment_Method` | string | Method of payment used | `Credit Card` |\n| `City` | string | Shipping/billing city | `New York` |\n| `Store_Type` | string | Type of store (online/physical) | `Online` |\n| `Discount_Applied` | boolean | Whether a discount was applied | `True` |\n| `Customer_Category` | string | Customer segment classification | `Premium` |\n| `Season` | string | Season of purchase | `Winter` |\n| `Promotion` | string | Promotion/coupon code used | `SAVE20` |\n\n---\n\n### Secondary Dataset: `cleaned_transactions.csv` / `.json`\n\n| Column | Data Type | Description | Transformation Applied |\n|--------|-----------|-------------|------------------------|\n| `transaction_id` | string | Unique transaction identifier | Renamed from `Transaction_ID` |\n| `date` | string | Purchase date | No change |\n| `customer_name` | string | Customer name (cleaned) | `strip().title()` applied |\n| `product` | string | Product name (cleaned) | `strip().title()` applied |\n| `quantity` | integer | Items purchased | Converted to int, default 0 |\n| `price` | float | Transaction total | Converted to float, default 0.0 |\n| `city` | string | City (cleaned) | `strip().title()` applied |\n| `promotion` | string | Promo code (cleaned) | `strip().upper()` applied |\n| `discount_pct` | integer | **Derived field** - extracted discount % | Regex extraction from promotion |\n\n---\n\n### Derived Features (TransactionWithFeatures class)\n\n| Property | Data Type | Description | Computation |\n|----------|-----------|-------------|-------------|\n| `days_since_purchase` | integer | Days between purchase and today | `date.today() - purchase_date` |\n| `discount_amount` | float | Discount in dollars | `(discount_pct / 100) * price` |",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}