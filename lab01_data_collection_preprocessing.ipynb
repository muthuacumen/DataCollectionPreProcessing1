{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 01: Data Collection and Preprocessing\n",
    "\n",
    "This notebook demonstrates fundamental data collection and preprocessing techniques using Python and pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Load the Dataset\n",
    "\n",
    "In this step, we load the retail transactions CSV file using pandas and inspect the first few rows to understand the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import pandas library\nimport pandas as pd\n\n# Load the CSV file into a DataFrame\ndf = pd.read_csv('data/Retail_Transactions_Dataset.csv')\n\n# Display the first 3 rows\ndf.head(3)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Data Structure Choice\n",
    "\n",
    "### Why pandas DataFrame?\n",
    "\n",
    "We use a **pandas DataFrame** to store our retail transactions data for the following reasons:\n",
    "\n",
    "| Criteria | DataFrame Advantage |\n",
    "|----------|---------------------|\n",
    "| **Tabular format** | CSV data is naturally row-column structured; DataFrames mirror this exactly |\n",
    "| **Mixed data types** | Our dataset contains strings (`Product`, `City`), numbers (`Total_Cost`, `Total_Items`), and dates (`Date`) ‚Äî DataFrames handle heterogeneous columns efficiently |\n",
    "| **Built-in methods** | Pandas provides optimized functions for filtering, grouping, aggregating, and cleaning data |\n",
    "| **Memory efficiency** | DataFrames use NumPy arrays under the hood, enabling vectorized operations |\n",
    "| **Ecosystem integration** | Seamless compatibility with visualization libraries (matplotlib, seaborn) and ML frameworks (scikit-learn) |\n",
    "\n",
    "### Alternatives Considered\n",
    "\n",
    "- **Python lists/dicts**: No built-in support for column operations or missing data handling\n",
    "- **NumPy arrays**: Require homogeneous data types; not ideal for mixed-type tabular data\n",
    "- **SQL database**: Overkill for a single-file analysis; adds setup complexity\n",
    "\n",
    "**Conclusion**: pandas DataFrame is the optimal choice for exploratory data analysis and preprocessing of structured CSV data."
   ]
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Step 3: Transaction Class\n\nWe define a `Transaction` class to encapsulate individual transaction records. This provides:\n- **Encapsulation**: Each transaction is a self-contained object\n- **Data cleaning**: The `clean()` method standardizes and sanitizes field values\n- **Calculations**: The `total()` method computes the transaction total",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class Transaction:\n    \"\"\"\n    Represents a single retail transaction.\n    \n    Attributes:\n        transaction_id: Unique identifier for the transaction\n        date: Date of the transaction\n        customer_name: Name of the customer\n        product: Product purchased\n        quantity: Number of items (Total_Items)\n        price: Cost of the transaction (Total_Cost)\n        city: City where the transaction occurred\n        promotion: Promotion/coupon code applied\n    \"\"\"\n    \n    def __init__(self, row):\n        \"\"\"Initialize a Transaction from a DataFrame row.\"\"\"\n        self.transaction_id = row.get('Transaction_ID', None)\n        self.date = row.get('Date', None)\n        self.customer_name = row.get('Customer_Name', None)\n        self.product = row.get('Product', None)\n        self.quantity = row.get('Total_Items', 0)\n        self.price = row.get('Total_Cost', 0.0)\n        self.city = row.get('City', None)\n        self.promotion = row.get('Promotion', None)\n    \n    def clean(self):\n        \"\"\"\n        Clean and standardize transaction data.\n        \n        Returns:\n            self: The Transaction instance (for method chaining)\n        \"\"\"\n        # Strip whitespace from string fields\n        if isinstance(self.customer_name, str):\n            self.customer_name = self.customer_name.strip().title()\n        \n        if isinstance(self.product, str):\n            self.product = self.product.strip().title()\n        \n        if isinstance(self.city, str):\n            self.city = self.city.strip().title()\n        \n        if isinstance(self.promotion, str):\n            self.promotion = self.promotion.strip().upper()\n        \n        # Handle missing/invalid numeric values\n        try:\n            self.quantity = int(self.quantity) if self.quantity else 0\n        except (ValueError, TypeError):\n            self.quantity = 0\n        \n        try:\n            self.price = float(self.price) if self.price else 0.0\n        except (ValueError, TypeError):\n            self.price = 0.0\n        \n        return self\n    \n    def total(self):\n        \"\"\"\n        Calculate the transaction total.\n        \n        Returns:\n            float: The total cost of the transaction\n        \"\"\"\n        return float(self.price)\n    \n    def __repr__(self):\n        \"\"\"String representation for debugging.\"\"\"\n        return f\"Transaction(id={self.transaction_id}, product={self.product}, total={self.total():.2f})\"\n\n\n# --- Demo: Create and clean a Transaction ---\n# Get the first row as a dictionary\nsample_row = df.iloc[0].to_dict()\n\n# Create a Transaction object\ntxn = Transaction(sample_row)\n\n# Clean the transaction data\ntxn.clean()\n\n# Display the transaction\nprint(f\"Transaction ID: {txn.transaction_id}\")\nprint(f\"Customer:       {txn.customer_name}\")\nprint(f\"Product:        {txn.product}\")\nprint(f\"Quantity:       {txn.quantity}\")\nprint(f\"City:           {txn.city}\")\nprint(f\"Promotion:      {txn.promotion}\")\nprint(f\"Total:          ${txn.total():.2f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Step 4: Bulk Load Transactions\n\nConvert the entire DataFrame into a list of `Transaction` objects. This demonstrates:\n- Iterating over DataFrame rows\n- Creating objects in bulk\n- Applying the `clean()` method to each transaction",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Convert DataFrame rows to a list of Transaction objects\n# Each row becomes a Transaction, then we call clean() on it\n\ntransactions = []\n\nfor index, row in df.iterrows():\n    # Convert row to dictionary and create Transaction\n    txn = Transaction(row.to_dict())\n    \n    # Clean the transaction data\n    txn.clean()\n    \n    # Add to list\n    transactions.append(txn)\n\n# Display summary\nprint(f\"Total transactions loaded: {len(transactions):,}\")\nprint(f\"\\nFirst 3 transactions:\")\nfor t in transactions[:3]:\n    print(f\"  {t}\")\n\nprint(f\"\\nLast 3 transactions:\")\nfor t in transactions[-3:]:\n    print(f\"  {t}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Step 5: Data Profiling\n\nCompute basic statistics to understand the dataset:\n- **Price statistics**: min, mean, max\n- **Unique cities**: count of distinct shipping locations",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Extract prices from all transactions\nprices = [t.price for t in transactions]\n\n# Compute price statistics\nmin_price = min(prices)\nmax_price = max(prices)\nmean_price = sum(prices) / len(prices)\n\n# Get unique cities\ncities = set(t.city for t in transactions)\nunique_city_count = len(cities)\n\n# Display profiling results\nprint(\"=\" * 40)\nprint(\"DATA PROFILING RESULTS\")\nprint(\"=\" * 40)\n\nprint(f\"\\nüìä Price Statistics:\")\nprint(f\"   Min:  ${min_price:,.2f}\")\nprint(f\"   Mean: ${mean_price:,.2f}\")\nprint(f\"   Max:  ${max_price:,.2f}\")\n\nprint(f\"\\nüèôÔ∏è City Statistics:\")\nprint(f\"   Unique cities: {unique_city_count}\")\n\nprint(f\"\\nüìã Sample cities:\")\nfor city in sorted(cities)[:5]:\n    print(f\"   - {city}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Step 6: Identify Dirty Data\n\nBefore cleaning, we analyze the raw DataFrame to identify data quality issues:\n- **Missing values**: Null or NaN entries\n- **Duplicates**: Repeated transaction IDs\n- **Invalid values**: Negative prices, zero quantities\n- **Inconsistent formatting**: Mixed case, extra whitespace",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ============================================\n# DIRTY DATA IDENTIFICATION\n# ============================================\n\nprint(\"=\" * 50)\nprint(\"DIRTY DATA REPORT\")\nprint(\"=\" * 50)\n\n# --- 1. Missing Values ---\nprint(\"\\n1Ô∏è‚É£ MISSING VALUES\")\nprint(\"-\" * 30)\nmissing_counts = df.isnull().sum()\ntotal_missing = missing_counts.sum()\n\nif total_missing > 0:\n    for col, count in missing_counts.items():\n        if count > 0:\n            pct = (count / len(df)) * 100\n            print(f\"   {col}: {count:,} ({pct:.2f}%)\")\nelse:\n    print(\"   No missing values found\")\n\n# --- 2. Duplicate Transaction IDs ---\nprint(\"\\n2Ô∏è‚É£ DUPLICATE TRANSACTION IDs\")\nprint(\"-\" * 30)\nduplicate_ids = df[df.duplicated(subset=['Transaction_ID'], keep=False)]\ndup_count = len(duplicate_ids)\n\nif dup_count > 0:\n    print(f\"   Count: {dup_count:,} rows with duplicate IDs\")\n    print(f\"   Examples:\")\n    dup_examples = duplicate_ids['Transaction_ID'].value_counts().head(3)\n    for tid, cnt in dup_examples.items():\n        print(f\"      ID {tid}: appears {cnt} times\")\nelse:\n    print(\"   No duplicate Transaction IDs found\")\n\n# --- 3. Invalid Prices ---\nprint(\"\\n3Ô∏è‚É£ INVALID PRICES (negative or zero)\")\nprint(\"-\" * 30)\ninvalid_prices = df[df['Total_Cost'] <= 0]\ninv_price_count = len(invalid_prices)\n\nif inv_price_count > 0:\n    print(f\"   Count: {inv_price_count:,}\")\n    print(f\"   Examples:\")\n    for idx, row in invalid_prices.head(3).iterrows():\n        print(f\"      Row {idx}: ${row['Total_Cost']}\")\nelse:\n    print(\"   No invalid prices found\")\n\n# --- 4. Invalid Quantities ---\nprint(\"\\n4Ô∏è‚É£ INVALID QUANTITIES (zero or negative)\")\nprint(\"-\" * 30)\ninvalid_qty = df[df['Total_Items'] <= 0]\ninv_qty_count = len(invalid_qty)\n\nif inv_qty_count > 0:\n    print(f\"   Count: {inv_qty_count:,}\")\n    print(f\"   Examples:\")\n    for idx, row in invalid_qty.head(3).iterrows():\n        print(f\"      Row {idx}: {row['Total_Items']} items\")\nelse:\n    print(\"   No invalid quantities found\")\n\n# --- 5. Whitespace Issues ---\nprint(\"\\n5Ô∏è‚É£ WHITESPACE ISSUES (leading/trailing spaces)\")\nprint(\"-\" * 30)\nstring_cols = ['Customer_Name', 'Product', 'City', 'Promotion']\nwhitespace_issues = 0\n\nfor col in string_cols:\n    if col in df.columns:\n        # Check for leading/trailing whitespace\n        has_whitespace = df[col].astype(str).str.contains(r'^\\s+|\\s+$', regex=True, na=False)\n        count = has_whitespace.sum()\n        if count > 0:\n            whitespace_issues += count\n            example = df.loc[has_whitespace, col].iloc[0] if count > 0 else \"N/A\"\n            print(f\"   {col}: {count:,} rows\")\n            print(f\"      Example: '{example}'\")\n\nif whitespace_issues == 0:\n    print(\"   No whitespace issues found\")\n\n# --- Summary ---\nprint(\"\\n\" + \"=\" * 50)\nprint(\"SUMMARY\")\nprint(\"=\" * 50)\nprint(f\"   Total rows:              {len(df):,}\")\nprint(f\"   Missing values:          {total_missing:,}\")\nprint(f\"   Duplicate IDs:           {dup_count:,}\")\nprint(f\"   Invalid prices:          {inv_price_count:,}\")\nprint(f\"   Invalid quantities:      {inv_qty_count:,}\")\nprint(f\"   Whitespace issues:       {whitespace_issues:,}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}